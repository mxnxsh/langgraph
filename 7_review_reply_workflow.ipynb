{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ad42289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, Literal\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64f30a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "291ed842",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model = 'gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f54a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSchema(BaseModel):\n",
    "  sentiment: Literal[\"positive\", \"negative\"] = Field(description=\"Sentiment of the review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "263f1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description='The category of issue mentioned in the review')\n",
    "    tone: Literal[\"angry\", \"frustrated\", \"disappointed\", \"calm\"] = Field(description='The emotional tone expressed by the user')\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description='How urgent or critical the issue appears to be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a41cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(SentimentSchema)\n",
    "structured_model2 = model.with_structured_output(DiagnosisSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "856eab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is the sentiment of the following review - The software too bad.\"\n",
    "\n",
    "structured_model.invoke(prompt).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5832614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewState(TypedDict):\n",
    "  review: str\n",
    "  sentiment: Literal[\"positive\", \"negative\"]\n",
    "  diagnosis: dict\n",
    "  response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c2e821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state: ReviewState):\n",
    "\n",
    "  prompt = f'For the following review find out the sentiment \\n {state[\"review\"]}'\n",
    "  sentiment = structured_model.invoke(prompt).sentiment\n",
    "\n",
    "  return {'sentiment': sentiment}\n",
    "\n",
    "def check_sentiment(state:ReviewState) -> Literal[\"positive_response\",\"run_diagnosis\"]:\n",
    "  if state[\"review\"] == 'positive':\n",
    "    return \"positive_response\"\n",
    "  else:\n",
    "    return \"run_diagnosis\"\n",
    "\n",
    "def positive_response(state: ReviewState):\n",
    "  prompt = f\"\"\"Write a warm thank-you message in response to this review:\n",
    "    \\n\\n\\\"{state['review']}\\\"\\n\n",
    "Also, kindly ask the user to leave feedback on our website.\"\"\"\n",
    "    \n",
    "  response = model.invoke(prompt).content\n",
    "\n",
    "  return {'response': response}\n",
    "\n",
    "def run_diagnosis(state: ReviewState):\n",
    "\n",
    "  prompt = f\"\"\"Diagnose this negative review:\\n\\n{state['review']}\\n\"\n",
    "    \"Return issue_type, tone, and urgency.\n",
    "\"\"\"\n",
    "  response = structured_model2.invoke(prompt)\n",
    "\n",
    "  return {'diagnosis': response.model_dump()}\n",
    "\n",
    "def negative_response(state: ReviewState):\n",
    "  diagnosis = state['diagnosis']\n",
    "\n",
    "  prompt = f\"\"\"You are a support assistant.\n",
    "The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'.\n",
    "Write an empathetic, helpful resolution message.\n",
    "\"\"\"\n",
    "  response = model.invoke(prompt).content\n",
    "\n",
    "  return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8cab0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ReviewState)\n",
    "\n",
    "graph.add_node(\"find_sentiment\", find_sentiment)\n",
    "graph.add_node('positive_response', positive_response)\n",
    "graph.add_node('run_diagnosis', run_diagnosis)\n",
    "graph.add_node('negative_response', negative_response)\n",
    "\n",
    "graph.add_edge(START, \"find_sentiment\")\n",
    "graph.add_conditional_edges(\"find_sentiment\", check_sentiment)\n",
    "graph.add_edge(\"positive_response\", END)\n",
    "graph.add_edge(\"run_diagnosis\",\"negative_response\")\n",
    "graph.add_edge(\"negative_response\", END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83110ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "64a269d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'I’ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.',\n",
       " 'sentiment': 'negative',\n",
       " 'diagnosis': {'issue_type': 'Bug', 'tone': 'frustrated', 'urgency': 'high'},\n",
       " 'response': \"Subject: We're Here to Help with Your Bug Issue\\n\\nHi [User's Name],\\n\\nI truly understand how frustrating it can be to encounter a bug, especially when it disrupts your work. I want to assure you that we’re here to assist you and resolve this issue as quickly as possible.\\n\\nCould you please provide a few more details about the error you’re experiencing? Specific information—such as what you were doing when the bug occurred, any error messages you received, and the platform or device you’re using—will help us diagnose the issue more effectively.\\n\\nYour urgency means a lot to us, and we will prioritize your case to ensure you get back on track without further delay. Thank you for your patience as we work together to fix this.\\n\\nLooking forward to your response!\\n\\nBest regards,  \\n[Your Name]  \\n[Your Position]  \\n[Your Contact Information]  \"}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intial_state={\n",
    "    'review': \"I’ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.\"\n",
    "}\n",
    "workflow.invoke(intial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
